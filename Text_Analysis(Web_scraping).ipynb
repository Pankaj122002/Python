{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8poiIbWxG23Csh3rmXCmT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pankaj122002/Python/blob/main/Text_Analysis(Web_scraping).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSsjIZYSh7nf",
        "outputId": "ac45a4b5-9abd-4311-947f-ac42f475798a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.4.1)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.1)\n",
            "Collecting syllables\n",
            "  Downloading syllables-1.0.7-py3-none-any.whl (15 kB)\n",
            "Collecting cmudict<2.0.0,>=1.0.11 (from syllables)\n",
            "  Downloading cmudict-1.0.13-py3-none-any.whl (939 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.3/939.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata<6.0.0,>=5.1.0 (from syllables)\n",
            "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
            "Collecting importlib-resources<6.0.0,>=5.10.1 (from cmudict<2.0.0,>=1.0.11->syllables)\n",
            "  Downloading importlib_resources-5.13.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->syllables) (3.16.2)\n",
            "Installing collected packages: importlib-resources, importlib-metadata, cmudict, syllables\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 6.0.1\n",
            "    Uninstalling importlib-resources-6.0.1:\n",
            "      Successfully uninstalled importlib-resources-6.0.1\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.8.0\n",
            "    Uninstalling importlib-metadata-6.8.0:\n",
            "      Successfully uninstalled importlib-metadata-6.8.0\n",
            "Successfully installed cmudict-1.0.13 importlib-metadata-5.2.0 importlib-resources-5.13.0 syllables-1.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install requests\n",
        "!pip install beautifulsoup4\n",
        "!pip install textblob\n",
        "!pip install syllables"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLssXW04rG3U",
        "outputId": "b30bb290-9575-4757-bf5e-3417459df543"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_df = pd.read_excel('/content/Input.xlsx')\n",
        "\n",
        "# Initialize a list to store analysis results\n",
        "\n",
        "results = []\n",
        "\n",
        "# Iterate through each row in the input DataFrame\n",
        "for index, row in input_df.iterrows():\n",
        "    url_id = row['URL_ID']\n",
        "    url = row['URL']\n",
        "    def extract_article_text(url):\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Find and extract the article title and text\n",
        "        article_text = \"\"\n",
        "        article_title = soup.find('title').get_text()\n",
        "        paragraphs = soup.find_all(['p', 'div'])  # Adjust based on the actual structure\n",
        "        for p in paragraphs:\n",
        "            article_text += p.get_text()\n",
        "        return article_title, article_text\n",
        "    article_title, article_text = extract_article_text(url)\n",
        "    # Perform text analysis using TextBlob\n",
        "    b = TextBlob(article_text)\n",
        "    positive_score = b.sentiment.polarity\n",
        "    negative_score = b.sentiment.polarity\n",
        "    polarity_score = b.sentiment.polarity\n",
        "    subjectivity_score = b.sentiment.subjectivity\n",
        "    avg_sentence_length = len(b.words) / len(b.sentences)\n",
        "    import re\n",
        "    def count_syllables(word):\n",
        "    # Convert the word to lowercase\n",
        "        word = word.lower()\n",
        "\n",
        "    # Define a regular expression to match consecutive vowels\n",
        "    # but not ending with 'e'\n",
        "        pattern = '(?!e$)[aeiouy]+'\n",
        "\n",
        "    # Find all matches of the pattern in the word\n",
        "        matches = re.findall(pattern, word, re.I)\n",
        "\n",
        "    # Return the count of matches (syllables)\n",
        "        return len(matches)\n",
        "\n",
        "\n",
        "    word = \"syllable\"\n",
        "    syllable_count = count_syllables(word)\n",
        "    def count_complex_words(b):\n",
        "        complex_word_count = sum(1 for word in b.words if syllable_count >= 3)\n",
        "        return complex_word_count\n",
        "    complex_word_count = count_complex_words(b)\n",
        "    percentage_complex_words = (complex_word_count / len(b.words)) * 100\n",
        "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
        "    avg_words_per_sentence = len(b.words) / len(b.sentences)\n",
        "    word_count = len(b.words)\n",
        "    avg_syllables_per_word = syllable_count / word_count\n",
        "    personal_pronoun_count = sum(1 for word in b.words if word.lower() in ['i', 'you', 'he', 'she', 'we', 'they'])\n",
        "    avg_word_length = sum(len(word) for word in b.words) / word_count\n",
        "\n",
        "\n",
        "    result = {\n",
        "        'URL_ID': url_id,\n",
        "        'POSITIVE SCORE': positive_score,\n",
        "        'NEGATIVE SCORE': negative_score,\n",
        "        'POLARITY SCORE': polarity_score,\n",
        "        'SUBJECTIVITY SCORE': subjectivity_score,\n",
        "        'AVG SENTENCE LENGTH': avg_sentence_length,\n",
        "        'PERCENTAGE OF COMPLEX WORDS': percentage_complex_words,\n",
        "        'FOG INDEX':fog_index,\n",
        "        'AVG NUMBER OF WORDS PER SENTENCE' :avg_words_per_sentence,\n",
        "        'COMPLEX WORD COUNT': complex_word_count,\n",
        "        'WORD COUNT': word_count,\n",
        "        'SYLLABLE PER WORD': avg_syllables_per_word,\n",
        "        'PERSONAL PRONOUNS': personal_pronoun_count,\n",
        "        'AVG WORD LENGTH': avg_word_length\n",
        "          }\n",
        "    results.append(result)\n",
        "output_df = pd.DataFrame(results)\n",
        "output_df.to_excel('output.xlsx', index=False)"
      ],
      "metadata": {
        "id": "ygRd11Dkuorg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_df)"
      ],
      "metadata": {
        "id": "B5fvhsNZzM-n",
        "outputId": "c68c8f09-f6e6-44c6-aaae-059f4f790d61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      URL_ID  POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  \\\n",
            "0      123.0        0.143031        0.143031        0.143031   \n",
            "1      321.0        0.138799        0.138799        0.138799   \n",
            "2     2345.0        0.112002        0.112002        0.112002   \n",
            "3     4321.0        0.150462        0.150462        0.150462   \n",
            "4      432.0        0.144979        0.144979        0.144979   \n",
            "..       ...             ...             ...             ...   \n",
            "109  50921.0        0.122659        0.122659        0.122659   \n",
            "110  51382.8        0.073174        0.073174        0.073174   \n",
            "111  51844.6        0.145176        0.145176        0.145176   \n",
            "112  52306.4        0.116704        0.116704        0.116704   \n",
            "113  52768.2        0.115631        0.115631        0.115631   \n",
            "\n",
            "     SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  \\\n",
            "0              0.384337            37.326121                          0.0   \n",
            "1              0.419228            62.300366                          0.0   \n",
            "2              0.384709            28.669021                          0.0   \n",
            "3              0.341231            42.638554                          0.0   \n",
            "4              0.340782            42.236686                          0.0   \n",
            "..                  ...                  ...                          ...   \n",
            "109            0.346614            57.466216                          0.0   \n",
            "110            0.355691            56.100686                          0.0   \n",
            "111            0.396833            40.706362                          0.0   \n",
            "112            0.366469            41.265918                          0.0   \n",
            "113            0.359298            50.168421                          0.0   \n",
            "\n",
            "     FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  \\\n",
            "0    14.930448                         37.326121                   0   \n",
            "1    24.920147                         62.300366                   0   \n",
            "2    11.467608                         28.669021                   0   \n",
            "3    17.055422                         42.638554                   0   \n",
            "4    16.894675                         42.236686                   0   \n",
            "..         ...                               ...                 ...   \n",
            "109  22.986486                         57.466216                   0   \n",
            "110  22.440275                         56.100686                   0   \n",
            "111  16.282545                         40.706362                   0   \n",
            "112  16.506367                         41.265918                   0   \n",
            "113  20.067368                         50.168421                   0   \n",
            "\n",
            "     WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
            "0         24150           0.000083                389         5.763188  \n",
            "1         17008           0.000118                354         5.774635  \n",
            "2         28411           0.000070                457         5.601281  \n",
            "3         21234           0.000094                420         5.729538  \n",
            "4         21414           0.000093                420         5.695993  \n",
            "..          ...                ...                ...              ...  \n",
            "109       17010           0.000118                340         5.762845  \n",
            "110       24516           0.000082                354         5.480992  \n",
            "111       24953           0.000080                389         5.528634  \n",
            "112       22036           0.000091                480         5.584816  \n",
            "113       19064           0.000105                347         5.867551  \n",
            "\n",
            "[114 rows x 14 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gio9dFoexfG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s3VMrglsyPUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZfVgswe9zZ_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hjhS912Yzefs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Arn-TRWFU-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eWUabfElEunQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "zewZGq6mE7FI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uwKzen2yE-uB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}